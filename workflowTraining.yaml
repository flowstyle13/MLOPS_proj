name: Continuous Training

on:
  schedule:
    - cron: "0 0 * * *" # Run daily at midnight
  workflow_dispatch: # Allow manual triggering
  push:
    branches:
      - main

jobs:
  train:
    runs-on: windows-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Git user identity
      - name: Configure Git User
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      # Step 3: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      # Step 4: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dvc[all]
          pip install -r requirements.txt

      # Step 5: Configure Google Drive credentials
      - name: Configure Google Drive credentials
        env:
          GDRIVE_SERVICE_ACCOUNT_BASE64: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_BASE64 }}
        run: |
          echo "${{ secrets.GDRIVE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > dvcML.json

      # Step 6: Configure DVC Remote for Google Drive
      - name: Configure DVC Remote
        run: |
          dvc remote modify storage gdrive_use_service_account true
          dvc remote modify --local storage gdrive_service_account_json_file_path dvcML.json

      # Step 7: Pull dataset from DVC remote
      - name: Pull dataset
        run: dvc pull

      # Step 8: Run data ingestion
      - name: Run Data Ingestion
        run: python src/data_ingestion.py

      # Step 9: Clean and merge new data
      - name: Clean and Merge New Data
        run: python src/data_cleaning.py

      # Step 10: Track updated dataset with DVC
      - name: Track Dataset with DVC
        run: |
          dvc add data/train.csv
          git add data/train.csv.dvc

      # Step 11: Commit dataset changes
      - name: Commit Dataset Changes
        run: git commit -m "Update training dataset with new data"

      # Step 12: Push dataset to DVC remote
      - name: Push Dataset to Remote
        run: dvc push

      # Step 13: Retrain the model
      - name: Retrain the Model
        run: python src/train_model.py

      # Step 14: Track updated model with DVC
      - name: Track Updated Model
        run: |
          dvc add model_pipeline.pkl
          git add model_pipeline.pkl.dvc

      # Step 15: Commit model changes
      - name: Commit Model Changes
        run: git commit -m "Update trained model"

      # Step 16: Push model to DVC remote
      - name: Push Model to Remote
        run: dvc push
